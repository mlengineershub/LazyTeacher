{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, EvalPrediction\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"BAAI/bge-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetDict(\n",
    "    {\n",
    "        \"train\": load_dataset(\"csv\", data_files=\"../data/train_oversampled.csv\", split=\"train\"),\n",
    "        \"validation\": load_dataset(\"csv\", data_files=\"../data/val_oversampled.csv\", split=\"train\"),\n",
    "        \"test\": load_dataset(\"csv\", data_files=\"../data/test.csv\", split=\"train\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'corrected_text', 'length', 'ratio_err', 'labels', 'is_generated'],\n",
       "        num_rows: 14803\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'corrected_text', 'length', 'ratio_err', 'labels', 'is_generated'],\n",
       "        num_rows: 3701\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['corrected_text', 'length', 'ratio_err', 'labels'],\n",
       "        num_rows: 3462\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"train\"] = data[\"train\"].remove_columns([\"Unnamed: 0\", \"length\", \"ratio_err\", \"is_generated\"])\n",
    "data[\"validation\"] = data[\"validation\"].remove_columns([\"Unnamed: 0\", \"length\", \"ratio_err\", \"is_generated\"])\n",
    "data[\"test\"] = data[\"test\"].remove_columns([\"length\", \"ratio_err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['corrected_text', 'labels'],\n",
       "        num_rows: 14803\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['corrected_text', 'labels'],\n",
       "        num_rows: 3701\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['corrected_text', 'labels'],\n",
       "        num_rows: 3462\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b42801815245dcbf790b32746ca6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f087d1d2b1f4278a3736f7f1c0d5cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7f9ad472c84a7ab7becdf0847ec4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda x: \n",
    "    {\n",
    "        \"text\": x[\"corrected_text\"]\n",
    "    },\n",
    "    remove_columns=[\"corrected_text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 14803\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 3701\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 3462\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BAAI/bge-small-en and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt,\n",
    "                                                           num_labels=6).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7f86432eda4014be5c3902283b82f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66daed3844244346ab42c37194c23a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3701 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad03caea8c5423b99abb6a6df16e6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds: EvalPrediction):\n",
    "    \"\"\"\n",
    "    Compute metrics for the task\n",
    "\n",
    "    Args:\n",
    "        preds {EvalPrediction}: the predictions from the model\n",
    "    Returns:\n",
    "        dict: a dictionary of metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = preds.label_ids\n",
    "    preds = preds.predictions.argmax(-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    weighted_precision = precision_score(labels, preds, average=\"weighted\")\n",
    "    weighted_recall = recall_score(labels, preds, average=\"weighted\")\n",
    "    weighted_f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "\n",
    "    macro_precision = precision_score(labels, preds, average=\"macro\")\n",
    "    macro_recall = recall_score(labels, preds, average=\"macro\")\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "\n",
    "    micro_precision = precision_score(labels, preds, average=\"micro\")\n",
    "    micro_recall = recall_score(labels, preds, average=\"micro\")\n",
    "    micro_f1 = f1_score(labels, preds, average=\"micro\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"weighted_precision\": weighted_precision,\n",
    "        \"weighted_recall\": weighted_recall,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"mcc\": mcc,\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"macro_recall\": macro_recall,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"micro_precision\": micro_precision,\n",
    "        \"micro_recall\": micro_recall,\n",
    "        \"micro_f1\": micro_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LS = len(data[\"train\"]) // BATCH_SIZE\n",
    "LR = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bge-small-en-finetuned-oversampled\",\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=LS,\n",
    "    learning_rate=LR,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=LS,\n",
    "    # load_best_model_at_end=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    lr_scheduler_type=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
